{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### This notebook was inspired from [medium](https://medium.com/)###and [here](https://www.kaggle.com/code/ammarnassanalhajali/layout-parser-model-training) ##and [here](https://www.kaggle.com/code/salmankhondker/starter-notebook-dl-sprint-2-0)##and [here](https://www.kaggle.com/code/ataullhasaim/mws-dl-enigma-1-0-starter-notebook)","metadata":{}},{"cell_type":"markdown","source":"This is only training code using detectron2","metadata":{}},{"cell_type":"code","source":"!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detectron2 imports\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\nfrom detectron2 import model_zoo\nimport cv2\nimport os\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset, LVISEvaluator\nfrom detectron2.data import build_detection_test_loader\nfrom detectron2.utils.visualizer import ColorMode\n\n# other libs (other necessary imports in Colab file to make the list shorter here)\n\nimport torch, torchvision\nfrom pathlib import Path\nimport torchvision.transforms as transforms","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#coco Data create and register\ndef create_data_pairs(input_path, detectron_img_path, detectron_annot_path, dir_type = 'train'):\n\n    img_paths = Path(input_path +'/train/images/').glob('*.jpg')\n\n    pairs = []\n    for img_path in img_paths:\n\n        file_name_tmp = str(img_path).split('/')[-1].split('.')\n        file_name_tmp.pop(-1)\n        file_name = '.'.join((file_name_tmp))\n\n        label_path = Path(input_path + '/train/labels/' + file_name + '.txt')\n\n        if label_path.is_file():\n\n            line_img = detectron_img_path + '/train/images/'+ file_name + '.jpg'\n            line_annot = detectron_annot_path+'/train/labels/' + file_name + '.txt'\n            pairs.append([line_img, line_annot])\n\n    return pairs\n\ninput_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\n\ndetectron_img_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\ndetectron_annot_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\n\ntrain = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'train')\nval = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'valid')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_coco_format(data_pairs):\n    \n    data_list = []\n\n    for i, path in enumerate(data_pairs):\n        \n        filename = path[0]\n\n        img_h, img_w = cv2.imread(filename).shape[:2]\n\n        img_item = {}\n        img_item['file_name'] = filename\n        img_item['image_id'] = i\n        img_item['height']= img_h\n        img_item['width']= img_w\n\n        #print(str(i), filename)\n\n\n        annotations = []\n        with open(path[1]) as annot_file:\n            lines = annot_file.readlines()\n            for line in lines:\n                if line[-1]==\"\\n\":\n                  box = line[:-1].split(' ')\n                else:\n                  box = line.split(' ')\n\n                class_id = box[0]\n                x_c = float(box[1])\n                y_c = float(box[2])\n                width = float(box[3])\n                height = float(box[4])\n\n                x1 = (x_c - (width/2)) * img_w\n                y1 = (y_c - (height/2)) * img_h\n                x2 = (x_c + (width/2)) * img_w\n                y2 = (y_c + (height/2)) * img_h\n\n                annotation = {\n                    \"bbox\": list(map(float,[x1, y1, x2, y2])),\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"category_id\": int(class_id),\n                    \"iscrowd\": 0\n                }\n                annotations.append(annotation)\n            img_item[\"annotations\"] = annotations\n        data_list.append(img_item)\n    return data_list \n\ntrain_list = create_coco_format(train)\nval_list = create_coco_format(val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for catalog_name, file_annots in [(\"train\", train_list), (\"val\", val_list)]:\n    DatasetCatalog.register(catalog_name, lambda file_annots = file_annots: file_annots)\n    MetadataCatalog.get(catalog_name).set(thing_classes=['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray'])\n\nmetadata = MetadataCatalog.get(\"train\") ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom augmentation function\ndef custom_mapper(dataset_dict):\n     dataset_dict = copy.deepcopy(dataset_dict)\n     image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n\n     transform_list = [T.RandomBrightness(0.5, 1.2),\n                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False)\n                      ]\n     image, transforms = T.apply_transform_gens(transform_list, image)\n\n     dataset_dict[\"image\"] = torch.as_tensor(\n        image.transpose(2, 0, 1).astype(\"float32\"))\n\n     annos = [\n        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n        for obj in dataset_dict.pop(\"annotations\")\n        if obj.get(\"iscrowd\", 0) == 0\n     ]\n     instances = utils.annotations_to_instances(annos, image.shape[:2])\n\n     dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n     return dataset_dict","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"train\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.DEVICE = 'cuda' # cuda\ncfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.CHECKPOINT_PERIOD = 750\ncfg.SOLVER.WARMUP_ITERS = 500\ncfg.SOLVER.GAMMA = 0.05\ncfg.SOLVER.BASE_LR = 0.0005\ncfg.DATALOADER.AUGMENTATIONS = [(\"CustomMapper\", custom_mapper),]\ncfg.SOLVER.MAX_ITER = 3500 # (train_size / batch_size) * 100\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # 512\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(\"train\").thing_classes)\ncfg.SOLVER.STEPS = (20500, )\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg)\ntrainer.resume_or_load(resume=False)\n\nimport time as t\ns1 = t.time()\ntry:\n  trainer.train()\nexcept:\n  None\ns2 = t.time()\nprint(s2-s1)","metadata":{},"execution_count":null,"outputs":[]}]}